{"cells": [ {"cell_type": "code", "execution_count": null, "id": "import-packages", "metadata": {}, "outputs": [], "source": [ "import pandas as pd\n", "import numpy as np\n", "from sklearn.preprocessing import LabelEncoder\n", "from xgboost import XGBRegressor\n", "from sklearn.metrics import mean_squared_error\n", "import os\n", "import tensorflow as tf\n", "# Optional: install mafese and mealpy if not present\n", "# !pip install mealpy mafese\n", "from mafese.wrapper.mha import MultiMhaSelector\n", "os.environ['XGB_USE_CPP_API'] = '0'\n", "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Use first GPU device\n", "def rrmse(y_true, y_pred):\n", "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n", "    mean_y = np.mean(y_true)\n", "    return rmse / mean_y\n", "def arrmse(y_true, y_pred):\n", "    n_targets = y_true.shape[1]\n", "    rrmse_scores = []\n", "    for i in range(n_targets):\n", "        rrmse_scores.append(rrmse(y_true[:, i], y_pred[:, i]))\n", "    return np.mean(rrmse_scores)\n" ] }, {"cell_type": "code", "execution_count": null, "id": "load-and-preprocess-data", "metadata": {}, "outputs": [], "source": [ "df = pd.read_csv('/kaggle/input/aq-bench/AQbench_dataset.csv')\n", "str_columns = df.select_dtypes(include=['object']).columns.tolist()\n", "str_columns = [col for col in str_columns if col != 'dataset']\n", "label_encoders = {}\n", "for col in str_columns:\n", "    le = LabelEncoder()\n", "    df[col] = le.fit_transform(df[col].astype(str).fillna('NaN'))\n", "    label_encoders[col] = le\n", "def sine_cosine_encode(values, period=None):\n", "    values_array = np.array(values)\n", "    if period is None:\n", "        period = values_array.max()\n", "    sin_values = np.sin(2 * np.pi * values_array / period)\n", "    cos_values = np.cos(2 * np.pi * values_array / period)\n", "    return sin_values, cos_values\n", "df['lonx'], df['lony'] = sine_cosine_encode(df['lon'], period=360)\n", "df = df.drop('lon', axis=1)\n", "var_df = pd.read_csv('/kaggle/input/aq-bench/AQbench_variables.csv')\n", "input_cols = var_df.loc[(var_df['input_target'] == 'input') & (var_df['column_name'] != 'lon'), 'column_name'].tolist()\n", "if 'lon' in input_cols:\n", "    input_cols.remove('lon')\n", "input_cols += ['lonx', 'lony']\n", "target_cols = var_df.loc[var_df['input_target'] == 'target', 'column_name'].tolist()\n", "x_train = df[df['dataset'] == 'train'][input_cols]\n", "y_train = df[df['dataset'] == 'train'][target_cols]\n", "x_test = df[df['dataset'] == 'test'][input_cols]\n", "y_test = df[df['dataset'] == 'test'][target_cols]\n", "x_val = df[df['dataset'] == 'val'][input_cols]\n", "y_val = df[df['dataset'] == 'val'][target_cols]\n", "df = df.drop('dataset', axis=1)\n", "x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape\n" ] }, {"cell_type": "code", "execution_count": null, "id": "train-xgboost-multi-target-gpu", "metadata": {}, "outputs": [], "source": [ "def train_xgboost_multi_target_gpu(x_train, y_train, x_val, y_val):\n", "    models = {}\n", "    predictions_val = np.zeros(y_val.shape)\n", "    for i, target in enumerate(y_train.columns):\n", "        print(f'Training {target}...')\n", "        model = XGBRegressor(tree_method='gpu_hist', predictor='gpu_predictor', n_estimators=100, verbosity=1)\n", "        model.fit(x_train, y_train[target], eval_set=[(x_val, y_val[target])], early_stopping_rounds=10, verbose=False)\n", "        models[target] = model\n", "        predictions_val[:, i] = model.predict(x_val)\n", "    average_val_rrmse = arrmse(y_val.values, predictions_val)\n", "    print(f'Average validation RRMSE: {average_val_rrmse}')\n", "    return models, predictions_val\n" ] }, {"cell_type": "code", "execution_count": null, "id": "mha-xgboost-experiment", "metadata": {}, "outputs": [], "source": [ "# MAFESE multi-MHA feature selection with XGBoost\n", "optimizers = MultiMhaSelector.SUPPORT['optimizer']\n", "results = {}\n", "for opt in optimizers:\n", "    print(f'Running {opt}...')\n", "    selector = MultiMhaSelector(problem='regression', obj_name='RMSE', estimator='xgb',\n", "                                list_optimizers=[opt], verbose=False)\n", "    selector.fit(x_train.values, y_train.values)\n", "    selected_indices = selector.selected_feature_indexes\n", "    if hasattr(selected_indices, 'tolist'):\n", "        selected_indices = selected_indices.tolist()\n", "    feat_subset = [input_cols[i] for i in selected_indices]\n", "    xgb_x_train = x_train[feat_subset]\n", "    xgb_x_val   = x_val[feat_subset]\n", "    preds = []\n", "    for tgt in y_train.columns:\n", "        model = XGBRegressor(tree_method='gpu_hist', predictor='gpu_predictor', n_estimators=100)\n", "        model.fit(xgb_x_train, y_train[tgt])\n", "        pred = model.predict(xgb_x_val)\n", "        preds.append(pred)\n", "    preds = np.column_stack(preds)\n", "    val_score = arrmse(y_val.values, preds)\n", "    print(f'{opt} validation ARRSME: {val_score}')\n", "    results[opt] = val_score\n", "results\n" ] } ], "metadata": { "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" }, "language_info": { "name": "python", "version": "3.12.11", "mimetype": "text/x-python", "codemirror_mode": { "name": "ipython", "version": 3 }, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py" } }, "nbformat": 4, "nbformat_minor": 4 }
