{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-and-data-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-and-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('data/AQbench_dataset.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "label-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "str_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "str_columns = [col for col in str_columns if col != 'dataset']\n",
    "label_encoders = {}\n",
    "for col in str_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str).fillna('NaN'))\n",
    "    label_encoders[col] = le\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cyclical-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sine_cosine_encode(values, period=None):\n",
    "    values_array = np.array(values)\n",
    "    if period is None:\n",
    "        period = values_array.max()\n",
    "    sin_values = np.sin(2 * np.pi * values_array / period)\n",
    "    cos_values = np.cos(2 * np.pi * values_array / period)\n",
    "    return sin_values, cos_values\n",
    "df['lonx'], df['lony'] = sine_cosine_encode(df['lon'], period=360)\n",
    "df = df.drop('lon', axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-dfs",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df = pd.read_csv('data/AQbench_variables.csv')\n",
    "input_cols = var_df.loc[(var_df['input_target'] == 'input') & (var_df['column_name'] != 'lon'), 'column_name'].tolist()\n",
    "if 'lon' in input_cols:\n",
    "    input_cols.remove('lon')\n",
    "input_cols += ['lonx', 'lony']\n",
    "target_cols = var_df.loc[var_df['input_target'] == 'target', 'column_name'].tolist()\n",
    "x_train = df[df['dataset'] == 'train'][input_cols]\n",
    "y_train = df[df['dataset'] == 'train'][target_cols]\n",
    "x_test = df[df['dataset'] == 'test'][input_cols]\n",
    "y_test = df[df['dataset'] == 'test'][target_cols]\n",
    "x_val = df[df['dataset'] == 'val'][input_cols]\n",
    "y_val = df[df['dataset'] == 'val'][target_cols]\n",
    "df = df.drop('dataset', axis=1)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tf-tpu-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle TPU-compatible TensorFlow model generator\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "hyper_df = pd.read_csv('data/hyperparameters.csv')\n",
    "# Connect to TPU\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    print('Running on TPU')\n",
    "except Exception as e:\n",
    "    tpu_strategy = tf.distribute.get_strategy()\n",
    "    print('TPU not found, defaulting to', strategy)\n",
    "def build_model(target):\n",
    "    row = hyper_df[hyper_df['column_name'] == target].iloc[0]\n",
    "    hidden_layers = eval(row['hidden layers'])\n",
    "    activation = row['activation']\n",
    "    loss = row['loss']\n",
    "    lr = float(row['learning rate'])\n",
    "    l2 = float(row['L2 lambda'])\n",
    "    input_dim = x_train.shape[1]\n",
    "    with tpu_strategy.scope():\n",
    "        model = keras.Sequential()\n",
    "        for h in hidden_layers:\n",
    "            model.add(layers.Dense(h, activation=activation, kernel_regularizer=keras.regularizers.l2(l2)))\n",
    "        model.add(layers.Dense(1))\n",
    "        model.build((None, input_dim))\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=loss)\n",
    "    return model\n",
    "# Example: pick a target and build/fit using its hyperparameters\n",
    "model = build_model('o3_average_values')\n",
    "history = model.fit(x_train, y_train['o3_average_values'],\n",
    "    batch_size=int(hyper_df[hyper_df['column_name']== 'o3_average_values']['batch size']),\n",
    "    epochs=int(hyper_df[hyper_df['column_name']== 'o3_average_values']['epochs']),\n",
    "    validation_data=(x_val, y_val['o3_average_values'])\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
